import re
import ast
from typing import List, Dict, Optional, Set

class BusinessRuleExtractor:
    """ä»è§£æçš„ä»£ç ä¸­æå–ä¸šåŠ¡è§„åˆ™ï¼ˆå¢å¼ºç‰ˆï¼‰"""

    def __init__(self, parsed_data: Dict):
        self.parsed_data = parsed_data
        self.business_rules = []

        # æ‰©å±•çš„ä¸šåŠ¡å…³é”®è¯å’Œæ¨¡å¼
        self.validation_keywords = {
            'validate', 'check', 'verify', 'ensure', 'require', 'must', 'should',
            'authorize', 'authenticate', 'permit', 'forbid', 'restrict', 'limit',
            'calculate', 'compute', 'transform', 'process', 'handle', 'filter'
        }

        self.business_entities = {
            'user', 'customer', 'order', 'product', 'item', 'restaurant', 'review',
            'payment', 'invoice', 'account', 'transaction', 'reservation', 'booking'
        }

        self.api_methods = {'get', 'post', 'put', 'delete', 'patch'}

    def extract_rules(self) -> List[Dict]:
        """ä»æ‰€æœ‰æ–‡ä»¶ä¸­æå–ä¸šåŠ¡è§„åˆ™ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        for file_info in self.parsed_data['files']:
            # 1. ä»å‡½æ•°ä¸­æå–
            for func in file_info['functions']:
                rules = self._extract_from_function_enhanced(func, file_info)
                self.business_rules.extend(rules)

            # 2. ä»ç±»ä¸­æå–
            for cls in file_info['classes']:
                rules = self._extract_from_class_enhanced(cls, file_info)
                self.business_rules.extend(rules)

            # 3. ä»æ–‡ä»¶æ•´ä½“æå–ï¼ˆå¦‚æ¨¡å‹å­—æ®µéªŒè¯ï¼‰
            file_rules = self._extract_from_file(file_info)
            self.business_rules.extend(file_rules)

        return self.business_rules

    def _extract_from_function_enhanced(self, func: Dict, file_info: Dict) -> List[Dict]:
        """å¢å¼ºç‰ˆå‡½æ•°è§„åˆ™æå–"""
        rules = []

        # æ£€æŸ¥1ï¼šå‡½æ•°åæ˜¯å¦åŒ…å«ä¸šåŠ¡å…³é”®è¯
        func_name_lower = func['name'].lower()
        for keyword in self.validation_keywords:
            if keyword in func_name_lower:
                rules.append({
                    'type': 'validation_function',
                    'file': file_info['file_path'],
                    'function_name': func['name'],
                    'line_number': func['line_start'],
                    'context': func['context_snippet'],
                    'docstring': func['docstring'],
                    'confidence': 'high',
                    'matched_keyword': keyword
                })
                break

        # æ£€æŸ¥2ï¼šæ˜¯å¦æ˜¯ä¸šåŠ¡æ“ä½œï¼ˆcreate, update, deleteç­‰ï¼‰
        operation_keywords = ['create_', 'add_', 'update_', 'delete_', 'remove_',
                             'get_', 'find_', 'search_', 'list_']
        for op in operation_keywords:
            if func_name_lower.startswith(op):
                # æ£€æŸ¥æ“ä½œçš„å¯¹è±¡æ˜¯å¦æ˜¯ä¸šåŠ¡å®ä½“
                for entity in self.business_entities:
                    if entity in func_name_lower:
                        rules.append({
                            'type': 'business_operation',
                            'file': file_info['file_path'],
                            'function_name': func['name'],
                            'line_number': func['line_start'],
                            'context': func['context_snippet'],
                            'docstring': func['docstring'],
                            'confidence': 'high',
                            'operation': op.rstrip('_'),
                            'entity': entity
                        })
                        break
                break

        # æ£€æŸ¥3ï¼šæ–‡æ¡£å­—ç¬¦ä¸²ä¸­çš„ä¸šåŠ¡è§„åˆ™
        if func.get('docstring'):
            doc_rules = self._extract_rules_from_docstring(
                func['docstring'], func, file_info, 'function'
            )
            rules.extend(doc_rules)

        # æ£€æŸ¥4ï¼šå‡½æ•°ä½“ä¸­çš„ä¸šåŠ¡è§„åˆ™
        if func.get('context_snippet'):
            code_rules = self._extract_rules_from_code(
                func['context_snippet'], func, file_info, 'function'
            )
            rules.extend(code_rules)

        # æ£€æŸ¥5ï¼šAPIç«¯ç‚¹ï¼ˆä½†éœ€è¦æå–å…¶ä¸­çš„ä¸šåŠ¡é€»è¾‘ï¼‰
        if func.get('is_api_endpoint', False):
            # æ·±å…¥åˆ†æAPIç«¯ç‚¹çš„å†…å®¹
            endpoint_rules = self._analyze_api_endpoint(func, file_info)
            rules.extend(endpoint_rules)

        return rules

    def _extract_from_class_enhanced(self, cls: Dict, file_info: Dict) -> List[Dict]:
        """å¢å¼ºç‰ˆç±»è§„åˆ™æå–"""
        rules = []

        # æ£€æŸ¥1ï¼šç±»åæ˜¯å¦è¡¨ç¤ºä¸šåŠ¡å®ä½“
        class_name_lower = cls['name'].lower()
        for entity in self.business_entities:
            if entity in class_name_lower:
                # æå–ç±»çº§åˆ«çš„ä¸šåŠ¡è§„åˆ™
                class_rule = {
                    'type': 'business_entity',
                    'file': file_info['file_path'],
                    'class_name': cls['name'],
                    'line_number': cls['line_start'],
                    'class_docstring': cls['docstring'],
                    'confidence': 'high',
                    'entity_type': entity
                }

                # ä»æ–‡æ¡£å­—ç¬¦ä¸²ä¸­æå–è§„åˆ™
                if cls.get('docstring'):
                    doc_rules = self._extract_rules_from_docstring(
                        cls['docstring'], cls, file_info, 'class'
                    )
                    class_rule['documented_rules'] = doc_rules

                # ä»å­—æ®µ/å±æ€§ä¸­æå–éªŒè¯è§„åˆ™
                field_rules = self._extract_field_rules(cls, file_info)
                if field_rules:
                    class_rule['field_rules'] = field_rules

                rules.append(class_rule)
                break

        # æ£€æŸ¥2ï¼šæ˜¯å¦æ˜¯æ•°æ®æ¨¡å‹ï¼ˆPydantic/SQLAlchemyï¼‰
        model_indicators = ['model', 'schema', 'table']
        if any(indicator in class_name_lower for indicator in model_indicators):
            # æå–æ¨¡å‹éªŒè¯è§„åˆ™
            model_rules = self._extract_model_rules(cls, file_info)
            rules.extend(model_rules)

        # æ£€æŸ¥3ï¼šç±»ä¸­çš„æ–¹æ³•
        for method in cls.get('methods', []):
            method_rules = self._extract_from_function_enhanced(method, file_info)
            for rule in method_rules:
                rule['parent_class'] = cls['name']
            rules.extend(method_rules)

        return rules

    def _extract_from_file(self, file_info: Dict) -> List[Dict]:
        """ä»æ–‡ä»¶æ•´ä½“å†…å®¹æå–è§„åˆ™"""
        rules = []
        file_path = file_info['file_path'].lower()

        # æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹å®šçš„ä¸šåŠ¡æ–‡ä»¶
        if any(entity in file_path for entity in self.business_entities):
            rules.append({
                'type': 'business_file',
                'file': file_info['file_path'],
                'description': f"ä¸šåŠ¡ç›¸å…³çš„æ–‡ä»¶ï¼ŒåŒ…å«{len(file_info['functions'])}ä¸ªå‡½æ•°å’Œ{len(file_info['classes'])}ä¸ªç±»",
                'confidence': 'medium'
            })

        return rules

    def _extract_rules_from_docstring(self, docstring: str, source: Dict,
                                    file_info: Dict, source_type: str) -> List[Dict]:
        """ä»æ–‡æ¡£å­—ç¬¦ä¸²ä¸­æå–ä¸šåŠ¡è§„åˆ™"""
        rules = []

        # æŸ¥æ‰¾å¸¸è§çš„ä¸šåŠ¡è§„åˆ™æ¨¡å¼
        patterns = [
            (r'(å¿…é¡»|should|must|required to|needs to)\s+(.+?)(?:ã€‚|\.)', 'requirement'),
            (r'(éªŒè¯|validate|check|verify)\s+(.+?)(?:ã€‚|\.)', 'validation'),
            (r'(è§„åˆ™|rule|policy|constraint)[ï¼š:]\s*(.+?)(?:ã€‚|\.)', 'policy'),
            (r'(å¦‚æœ|if)\s+(.+?)\s*(?:åˆ™|then)\s*(.+?)(?:ã€‚|\.)', 'condition'),
            (r'(æœ€å°|æœ€å°‘|at least|min(?:imum)?)\s*[:ï¼š]?\s*(\d+)', 'min_constraint'),
            (r'(æœ€å¤§|æœ€å¤š|at most|max(?:imum)?)\s*[:ï¼š]?\s*(\d+)', 'max_constraint'),
            (r'(åªèƒ½|only)\s+(.+?)(?:ã€‚|\.)', 'restriction'),
        ]

        for pattern, rule_type in patterns:
            matches = re.findall(pattern, docstring, re.IGNORECASE)
            for match in matches:
                if isinstance(match, tuple):
                    rule_text = ' '.join([m for m in match if m])
                else:
                    rule_text = match

                if len(rule_text) > 10:  # é¿å…å¤ªçŸ­çš„åŒ¹é…
                    rules.append({
                        'type': f'documented_{rule_type}',
                        'file': file_info['file_path'],
                        'source': source['name'] if source_type == 'function' else source['name'],
                        'source_type': source_type,
                        'rule_text': rule_text.strip(),
                        'confidence': 'medium'
                    })

        return rules

    def _extract_rules_from_code(self, code_snippet: str, source: Dict,
                               file_info: Dict, source_type: str) -> List[Dict]:
        """ä»ä»£ç ç‰‡æ®µä¸­æå–ä¸šåŠ¡è§„åˆ™"""
        rules = []

        # æŸ¥æ‰¾å¸¸è§çš„éªŒè¯ä»£ç æ¨¡å¼
        validation_patterns = [
            (r'if\s+not\s+(.+?):', 'null_check'),
            (r'if\s+len\((.+?)\)\s*[<>]=?\s*(\d+):', 'length_check'),
            (r'if\s+(.+?)\s*[<>]=?\s*(\d+):', 'value_check'),
            (r'assert\s+(.+?)', 'assertion'),
            (r'raise\s+(.+?)Exception', 'exception'),
            (r'\.validate\(', 'validation_call'),
            (r'Field\([^)]*(?:min|max|gt|lt|ge|le)[^)]*\)', 'field_validation'),
        ]

        lines = code_snippet.split('\n')
        for i, line in enumerate(lines):
            for pattern, rule_type in validation_patterns:
                match = re.search(pattern, line)
                if match:
                    rules.append({
                        'type': f'code_{rule_type}',
                        'file': file_info['file_path'],
                        'source': source['name'],
                        'source_type': source_type,
                        'line_content': line.strip(),
                        'line_in_snippet': i + 1,
                        'confidence': 'high',
                        'pattern_matched': pattern
                    })

        return rules

    def _analyze_api_endpoint(self, func: Dict, file_info: Dict) -> List[Dict]:
        """æ·±å…¥åˆ†æAPIç«¯ç‚¹ï¼Œæå–å…¶ä¸­çš„ä¸šåŠ¡é€»è¾‘"""
        rules = []

        # ä»ç«¯ç‚¹åç§°æ¨æ–­ä¸šåŠ¡æ“ä½œ
        endpoint_name = func['name'].lower()

        # æ˜ å°„å¸¸è§ç«¯ç‚¹æ¨¡å¼åˆ°ä¸šåŠ¡æ“ä½œ
        endpoint_patterns = [
            (r'create_(\w+)', 'create_operation'),
            (r'add_(\w+)', 'add_operation'),
            (r'update_(\w+)', 'update_operation'),
            (r'delete_(\w+)', 'delete_operation'),
            (r'get_(\w+)', 'read_operation'),
            (r'list_(\w+)', 'list_operation'),
        ]

        for pattern, operation_type in endpoint_patterns:
            match = re.match(pattern, endpoint_name)
            if match:
                entity = match.group(1)
                rules.append({
                    'type': 'api_business_operation',
                    'file': file_info['file_path'],
                    'endpoint': func['name'],
                    'operation': operation_type.replace('_operation', ''),
                    'entity': entity,
                    'line_number': func['line_start'],
                    'confidence': 'high',
                    'description': f"APIç«¯ç‚¹æ‰§è¡Œ{operation_type.replace('_', ' ')}æ“ä½œ"
                })
                break

        # ä»è£…é¥°å™¨æå–HTTPæ–¹æ³•å’Œè·¯å¾„
        for decorator in func.get('decorators', []):
            for method in self.api_methods:
                if f'.{method}(' in decorator or f'.{method}]' in decorator:
                    # æå–è·¯å¾„
                    path_match = re.search(r'["\'](/[^"\']+)["\']', decorator)
                    path = path_match.group(1) if path_match else 'unknown'

                    rules.append({
                        'type': 'api_endpoint_details',
                        'file': file_info['file_path'],
                        'endpoint': func['name'],
                        'http_method': method.upper(),
                        'path': path,
                        'line_number': func['line_start'],
                        'confidence': 'high'
                    })
                    break

        return rules

    def _extract_field_rules(self, cls: Dict, file_info: Dict) -> List[Dict]:
        """ä»ç±»å®šä¹‰ä¸­æå–å­—æ®µéªŒè¯è§„åˆ™"""
        rules = []
        context = cls.get('context_snippet', '')

        # æŸ¥æ‰¾Pydantic FieldéªŒè¯
        field_patterns = [
            (r'(\w+)\s*:\s*\w+\s*=\s*Field\([^)]*min_length\s*=\s*(\d+)', 'min_length'),
            (r'(\w+)\s*:\s*\w+\s*=\s*Field\([^)]*max_length\s*=\s*(\d+)', 'max_length'),
            (r'(\w+)\s*:\s*\w+\s*=\s*Field\([^)]*gt\s*=\s*(\d+)', 'greater_than'),
            (r'(\w+)\s*:\s*\w+\s*=\s*Field\([^)]*lt\s*=\s*(\d+)', 'less_than'),
            (r'(\w+)\s*:\s*\w+\s*=\s*Field\([^)]*ge\s*=\s*(\d+)', 'min_value'),
            (r'(\w+)\s*:\s*\w+\s*=\s*Field\([^)]*le\s*=\s*(\d+)', 'max_value'),
            (r'(\w+)\s*:\s*\w+\s*=\s*Field\([^)]*regex\s*=\s*[\'"]([^\'"]+)[\'"]', 'regex'),
        ]

        for pattern, rule_type in field_patterns:
            matches = re.findall(pattern, context)
            for match in matches:
                if isinstance(match, tuple) and len(match) >= 2:
                    field_name, constraint_value = match[0], match[1]
                    rules.append({
                        'type': f'field_{rule_type}',
                        'file': file_info['file_path'],
                        'class_name': cls['name'],
                        'field': field_name,
                        'constraint': f"{rule_type}: {constraint_value}",
                        'confidence': 'high'
                    })

        return rules

    def _extract_model_rules(self, cls: Dict, file_info: Dict) -> List[Dict]:
        """æå–æ•°æ®æ¨¡å‹è§„åˆ™"""
        rules = []

        # æ£€æŸ¥æ˜¯å¦æ˜¯SQLAlchemyæ¨¡å‹
        if any('Base' in base for base in cls.get('bases', [])):
            rules.append({
                'type': 'database_model',
                'file': file_info['file_path'],
                'class_name': cls['name'],
                'description': 'æ•°æ®åº“æ¨¡å‹ç±»',
                'total_fields': self._count_model_fields(cls),
                'confidence': 'medium'
            })

        # æ£€æŸ¥æ˜¯å¦æ˜¯Pydanticæ¨¡å‹
        if any('BaseModel' in base for base in cls.get('bases', [])):
            rules.append({
                'type': 'pydantic_model',
                'file': file_info['file_path'],
                'class_name': cls['name'],
                'description': 'æ•°æ®éªŒè¯æ¨¡å‹ç±»',
                'confidence': 'medium'
            })

        return rules

    def _count_model_fields(self, cls: Dict) -> int:
        """ä¼°ç®—æ¨¡å‹å­—æ®µæ•°é‡ï¼ˆé€šè¿‡åˆ†æç±»ä¸Šä¸‹æ–‡ï¼‰"""
        context = cls.get('context_snippet', '')
        # ç®€å•çš„å­—æ®µè®¡æ•°ï¼šæŸ¥æ‰¾å†’å·åçš„ç±»å‹æ³¨è§£
        field_pattern = r'\w+\s*:\s*\w+(\s*=\s*\w+)?'
        return len(re.findall(field_pattern, context))

    def get_summary(self) -> Dict:
        """è·å–æå–ç»“æœçš„è¯¦ç»†æ‘˜è¦"""
        rule_types = {}
        confidence_levels = {'high': 0, 'medium': 0, 'low': 0}
        files_analyzed = set()

        for rule in self.business_rules:
            rule_type = rule['type']
            rule_types[rule_type] = rule_types.get(rule_type, 0) + 1

            confidence = rule.get('confidence', 'medium')
            confidence_levels[confidence] = confidence_levels.get(confidence, 0) + 1

            files_analyzed.add(rule['file'])

        return {
            'total_rules': len(self.business_rules),
            'rule_types': rule_types,
            'confidence_distribution': confidence_levels,
            'files_analyzed': len(files_analyzed),
            'unique_sources': len(set(r.get('source', '') for r in self.business_rules if r.get('source')))
        }

    def print_detailed_report(self):
        """æ‰“å°è¯¦ç»†çš„æå–æŠ¥å‘Š"""
        summary = self.get_summary()

        print(f"\n{'='*60}")
        print(f"{'ä¸šåŠ¡è§„åˆ™æå–è¯¦ç»†æŠ¥å‘Š':^60}")
        print(f"{'='*60}")

        print(f"\nğŸ“Š ç»Ÿè®¡æ‘˜è¦:")
        print(f"  â€¢ æ€»å…±æå–åˆ° {summary['total_rules']} æ¡ä¸šåŠ¡è§„åˆ™")
        print(f"  â€¢ åˆ†æäº† {summary['files_analyzed']} ä¸ªæ–‡ä»¶")
        print(f"  â€¢ ç½®ä¿¡åº¦åˆ†å¸ƒ: {summary['confidence_distribution']}")

        print(f"\nğŸ“ è§„åˆ™ç±»å‹åˆ†å¸ƒ:")
        for rule_type, count in summary['rule_types'].items():
            print(f"  â€¢ {rule_type}: {count} æ¡")

        print(f"\nğŸ” è¯¦ç»†è§„åˆ™ç¤ºä¾‹ (å‰10æ¡):")
        for i, rule in enumerate(self.business_rules[:10]):
            print(f"\n  [{i+1}] {rule['type']} (ç½®ä¿¡åº¦: {rule.get('confidence', 'N/A')})")
            print(f"      æ–‡ä»¶: {rule['file']}")

            if 'function_name' in rule:
                print(f"      å‡½æ•°: {rule['function_name']}")
            elif 'class_name' in rule:
                print(f"      ç±»: {rule['class_name']}")

            if 'description' in rule:
                print(f"      æè¿°: {rule['description']}")
            elif 'rule_text' in rule:
                print(f"      è§„åˆ™: {rule['rule_text'][:80]}...")

            if 'line_number' in rule:
                print(f"      è¡Œå·: {rule['line_number']}")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # 1. é¦–å…ˆè¿è¡Œä»£ç è§£æå™¨
    from code_parser import CodeParser

    REPO_PATH = "../test_repo"
    parser = CodeParser(REPO_PATH)
    parsed_data = parser.parse_repository()

    # 2. è¿è¡Œä¸šåŠ¡è§„åˆ™æå–å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰
    extractor = BusinessRuleExtractor(parsed_data)
    business_rules = extractor.extract_rules()

    # 3. æ‰“å°è¯¦ç»†æŠ¥å‘Š
    extractor.print_detailed_report()

    # 4. ä¿å­˜æå–ç»“æœ
    import json
    output_path = "../data/business_rules_enhanced.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump({
            'summary': extractor.get_summary(),
            'rules': business_rules
        }, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
